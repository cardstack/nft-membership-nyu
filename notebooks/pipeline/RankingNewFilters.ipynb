{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a863de5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run Imports.ipynb\n",
    "#install boto3, s3fs\n",
    "\n",
    "AWS_ACCESS_KEY_ID = \"<access_key>\"\n",
    "AWS_SECRET_ACCESS_KEY = \"<secret_key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17815b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.app.name\",\"s3app1\").\\\n",
    "    config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:3.2.0,org.apache.hadoop:hadoop-common:3.2.0\").\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39295d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\",AWS_ACCESS_KEY_ID)\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\",AWS_SECRET_ACCESS_KEY)\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.aws.credentials.provider\", \\\n",
    "                                     \"com.amazonaws.auth.InstanceProfileCredentialsProvider,com.amazonaws.auth.DefaultAWSCredentialsProviderChain\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.AbstractFileSystem.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d0cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = \"s3a://nft-membership-nyu-dune/source/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e67153d",
   "metadata": {},
   "source": [
    "# Removing Bot Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d415c0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"Load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df890b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage_1 = spark.sql(\"SELECT * FROM Load Where buyer NOT IN \\\n",
    "                       (SELECT buyer FROM (SELECT buyer, count(buyer) as counter from Load \\\n",
    "                       GROUP BY buyer, (EXTRACT(HOUR FROM block_time)), (EXTRACT(MINUTE FROM block_time))) temp\\\n",
    "                       WHERE counter > 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage_1.createOrReplaceTempView(\"Load1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec33a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage_2 = spark.sql(\"SELECT * FROM Load1 Where buyer NOT IN \\\n",
    "                       (SELECT buyer FROM(SELECT a.buyer, a.original_amount, b.original_amount,(b.block_time - a.block_time) time_gap \\\n",
    "                        FROM Load1 a INNER JOIN Load1 b \\\n",
    "                        ON (a.buyer = b.seller AND a.block_time < b.block_time AND a.nft_token_id = b.nft_token_id )) \\\n",
    "                        WHERE (EXTRACT(MINUTES FROM time_gap)) < 1 AND (EXTRACT(HOURS FROM time_gap)) = 0 AND \\\n",
    "                       (EXTRACT(DAYS FROM time_gap)) = 0 ORDER BY time_gap ASC)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0949cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.sql.functions import avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09902d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage_2.createOrReplaceTempView(\"LoadData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381768bf",
   "metadata": {},
   "source": [
    "Main Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = spark.sql(\"SELECT * FROM ( SELECT n1.buyer, n1.original_currency, n1.nft_token_id, n1.nft_contract_address, n1.original_amount as Bought, n2.original_amount as Sold, n1.block_time as Bought_Timestamp, n2.block_time as Sold_Timestamp,n1.usd_amount as Bought_amount, n2.usd_amount as Sold_amount, (n2.usd_amount - n1.usd_amount) as net, n1.platform as n1platform, n2.platform as n2platform FROM LoadData n1, LoadData n2 where n1.buyer = n2.seller AND  n2.block_time > n1.block_time AND  n1.nft_token_id is not null AND n1.nft_token_id = n2.nft_token_id AND n1.nft_contract_address = n2.nft_contract_address) holdings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967caacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81195c",
   "metadata": {},
   "source": [
    "# Ranking 1 - Total Earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab080ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = df_all.groupBy(\"buyer\").agg(sum(\"net\").alias(\"total_earnings\"))\n",
    "df_avg_pd=df_avg.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels = ['Range 1', 'Range 2', 'Range 3', 'Range 4', 'Range 5']\n",
    "custom_bins = [df_avg.agg({'total_earnings': 'min'}).select(col('min(total_earnings)').cast('float')).first()[0], -50, 50, 1000, 10000, df_avg.agg({'total_earnings': 'max'}).select(col('max(total_earnings)').cast('float')).first()[0]]\n",
    "\n",
    "df_avg_pd[\"buckets\"] = pd.cut(df_avg_pd[\"total_earnings\"], bins=custom_bins, labels=bin_labels)\n",
    "\n",
    "# Convert the Interval object to a string representation of the bin interval\n",
    "df_avg_pd[\"buckets\"] = df_avg_pd[\"buckets\"].apply(lambda x: str(x))\n",
    "\n",
    "# Calculate the histogram of the binned column\n",
    "histogram = df_avg_pd.groupby(\"buckets\").size().reset_index(name=\"count\")\n",
    "histogram = histogram.sort_values(\"buckets\")\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Plot the histogram\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(histogram[\"buckets\"], histogram[\"count\"], width=1, edgecolor=\"black\", color=colors)\n",
    "ax.set_xlabel(\"Buckets\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Histogram of Binned Values for Ranking 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Plot the histogram\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(histogram[\"buckets\"], histogram[\"count\"], width=1, edgecolor=\"black\", color=colors)\n",
    "ax.set_xlabel(\"Buckets\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Histogram of Binned Values for Ranking 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_boundaries = [-float(\"inf\"),df_avg.agg({'total_earnings': 'min'}).select(col('min(total_earnings)').cast('float')).first()[0], -50, 50, 1000, 10000, df_avg.agg({'total_earnings': 'max'}).select(col('max(total_earnings)').cast('float')).first()[0], float(\"inf\")]\n",
    "\n",
    "# Use the Bucketizer function to split the data into ranges\n",
    "bucketizer = Bucketizer(splits=range_boundaries, inputCol=\"total_earnings\", outputCol=\"bins_sum_net\")\n",
    "df_bucketized_sum_net = bucketizer.transform(df_avg)\n",
    "\n",
    "# Group the data by the \"buyer\" column and the range index, and compute the average duration\n",
    "\n",
    "# Show the resulting DataFrame with the average duration per buyer and range\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa44472",
   "metadata": {},
   "source": [
    "# Ranking 2 - Amount Spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5bb5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_spent = df_stage_2.groupBy(\"buyer\").agg(sum(\"usd_amount\").alias(\"amount_spent\"))\n",
    "df_avg_spent_pd=df_avg_spent.toPandas()\n",
    "\n",
    "bin_labels = ['Range 1', 'Range 2', 'Range 3', 'Range 4', 'Range 5']\n",
    "custom_bins = [df_avg_spent.agg({'amount_spent': 'min'}).select(col('min(amount_spent)').cast('float')).first()[0], 100, 1000, 10000, 100000, df_avg_spent.agg({'amount_spent': 'max'}).select(col('max(amount_spent)').cast('float')).first()[0]]\n",
    "\n",
    "df_avg_spent_pd[\"buckets\"] = pd.cut(df_avg_spent_pd[\"amount_spent\"], bins=custom_bins, labels=bin_labels)\n",
    "\n",
    "# Convert the Interval object to a string representation of the bin interval\n",
    "df_avg_spent_pd[\"buckets\"] = df_avg_spent_pd[\"buckets\"].apply(lambda x: str(x))\n",
    "\n",
    "# Calculate the histogram of the binned column\n",
    "histogram = df_avg_spent_pd.groupby(\"buckets\").size().reset_index(name=\"count\")\n",
    "histogram = histogram.sort_values(\"buckets\")\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Plot the histogram\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(histogram[\"buckets\"], histogram[\"count\"], width=1, edgecolor=\"black\", color=colors)\n",
    "ax.set_xlabel(\"Buckets\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Histogram of Binned Values for Ranking 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ebe4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_boundaries = custom_bins\n",
    "#range_boundaries = [-float(\"inf\"),df_avg_spent.agg({'amount_spent': 'min'}).select(col('min(amount_spent)').cast('float')).first()[0], -50, 50, 1000, 10000, df_avg_spent.agg({'amount_spent': 'max'}).select(col('max(amount_spent)').cast('float')).first()[0], float(\"inf\")]\n",
    "\n",
    "# Use the Bucketizer function to split the data into ranges\n",
    "bucketizer = Bucketizer(splits=range_boundaries, inputCol=\"amount_spent\", outputCol=\"bins_spent\")\n",
    "df_bucketized_spent = bucketizer.transform(df_avg_spent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49396215",
   "metadata": {},
   "source": [
    "# Ranking 3 - number of transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb88e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df_stage_2.groupBy(\"buyer\").agg(count(\"*\").alias(\"number_txns\"))\n",
    "df_count_pd=df_count.toPandas()\n",
    "# df_count.select(\"number_txns\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b1c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the spread\n",
    "unique_values = df_count_pd['number_txns'].value_counts().to_frame().reset_index()\n",
    "unique_values.columns = ['unique_values', 'count']\n",
    "bin_labels = ['Range 1', 'Range 2', 'Range 3', 'Range 4', 'Range 5']\n",
    "custom_bins = [df_count.agg({'number_txns': 'min'}).select(col('min(number_txns)').cast('float')).first()[0], 2, 5, 10, 20, df_count.agg({'number_txns': 'max'}).select(col('max(number_txns)').cast('float')).first()[0]]\n",
    "df_count_pd[\"buckets\"] = pd.cut(df_count_pd[\"number_txns\"], bins=custom_bins, labels=bin_labels)\n",
    "df_count_pd[\"buckets\"] = df_count_pd[\"buckets\"].apply(lambda x: str(x))\n",
    "histogram = df_count_pd.groupby(\"buckets\").size().reset_index(name=\"count\")\n",
    "histogram = histogram.sort_values(\"buckets\")\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(histogram[\"buckets\"], histogram[\"count\"], width=1, edgecolor=\"black\", color=colors)\n",
    "ax.set_xlabel(\"Buckets\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Histogram of Binned Values for Ranking 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b219fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "range_boundaries = custom_bins\n",
    "\n",
    "bucketizer_ranking2 = Bucketizer(splits=range_boundaries, inputCol=\"number_txns\", outputCol=\"bins_number_txns\")\n",
    "df_bucketized_number_txns = bucketizer_ranking2.transform(df_count)\n",
    "# df_bucketized_number_txns.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349eb336",
   "metadata": {},
   "source": [
    "# Diversity Ranking 4 - Number of unique currencies transaction done in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17116c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_currency = df_all.groupBy(\"buyer\").agg(countDistinct(\"original_currency\").alias(\"num_currency\"))\n",
    "df_currency_pd=df_currency.toPandas()\n",
    "# df_currency.select(\"num_currency\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0291f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = df_currency_pd['num_currency'].value_counts().to_frame().reset_index()\n",
    "unique_values.columns = ['unique_values', 'count']\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b568bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels = ['Range 1', 'Range 2', 'Range 3', 'Range 4']\n",
    "custom_bins = [df_currency.agg({'num_currency': 'min'}).select(col('min(num_currency)').cast('float')).first()[0], 2, 3, 4, df_currency.agg({'num_currency': 'max'}).select(col('max(num_currency)').cast('float')).first()[0] + 2]\n",
    "df_currency_pd[\"buckets\"] = pd.cut(df_currency_pd[\"num_currency\"], bins=custom_bins, labels=bin_labels)\n",
    "df_currency_pd[\"buckets\"] = df_currency_pd[\"buckets\"].apply(lambda x: str(x))\n",
    "histogram = df_currency_pd.groupby(\"buckets\").size().reset_index(name=\"count\")\n",
    "histogram = histogram.sort_values(\"buckets\")\n",
    "colors = ['red', 'blue', 'green', 'yellow']\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(histogram[\"buckets\"], histogram[\"count\"], width=1, edgecolor=\"black\", color=colors)\n",
    "ax.set_xlabel(\"Buckets\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Histogram of Binned Values for Ranking 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec85ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_boundaries = custom_bins\n",
    "bucketizer_ranking4 = Bucketizer(splits=range_boundaries, inputCol=\"num_currency\", outputCol=\"bins_num_currency\")\n",
    "df_bucketized_df_currency = bucketizer_ranking4.transform(df_currency)\n",
    "# df_bucketized_df_currency.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7b98e",
   "metadata": {},
   "source": [
    "# Ranking 5 - Average Holding Duration (in seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed31f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.withColumn(\"duration\", (unix_timestamp(col(\"Sold_Timestamp\")) - unix_timestamp(col(\"Bought_Timestamp\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d650d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_duration = df_all.groupBy(\"buyer\").agg(avg(\"duration\").alias(\"avg_duration\"))\n",
    "# df_avg_duration.select(\"avg_duration\").describe().show()\n",
    "df_avg_duration_pd=df_avg_duration.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90303927",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_labels = ['Range 1', 'Range 2', 'Range 3', 'Range 4', 'Range 5']\n",
    "#in a day, in a week , in month, in year(max value)\n",
    "custom_bins = [0, 86400,604800,2628000, 31540000, df_avg_duration.agg({'avg_duration': 'max'}).select(col('max(avg_duration)').cast('float')).first()[0]]\n",
    "\n",
    "df_avg_duration_pd[\"buckets\"] = pd.cut(df_avg_duration_pd[\"avg_duration\"], bins=custom_bins, labels=bin_labels)\n",
    "df_avg_duration_pd[\"buckets\"] = df_avg_duration_pd[\"buckets\"].apply(lambda x: str(x))\n",
    "histogram = df_avg_duration_pd.groupby(\"buckets\").size().reset_index(name=\"count\")\n",
    "histogram = histogram.sort_values(\"buckets\")\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(histogram[\"buckets\"], histogram[\"count\"], width=1, edgecolor=\"black\", color=colors)\n",
    "ax.set_xlabel(\"Buckets\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Histogram of Binned Values for Ranking 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7591f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_boundaries = custom_bins\n",
    "bucketizer_ranking5 = Bucketizer(splits=range_boundaries, inputCol=\"avg_duration\", outputCol=\"bins_avg_duration\")\n",
    "df_bucketized_avg_duration = bucketizer_ranking5.transform(df_avg_duration)\n",
    "# df_bucketized_avg_duration.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f43872",
   "metadata": {},
   "source": [
    "# Ranking 6 - Number of NFT Contract Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0892df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nft = df_stage_2.groupBy(\"buyer\").agg(sum(\"number_of_items\").alias(\"number_of_items\"))\n",
    "df_nft_pd=df_nft.toPandas()\n",
    "\n",
    "bin_labels = ['Range 1', 'Range 2', 'Range 3', 'Range 4', 'Range 5']\n",
    "custom_bins = [0, 10, 20, 50, 100, df_nft.agg({'number_of_items': 'max'}).select(col('max(number_of_items)').cast('float')).first()[0]]\n",
    "\n",
    "df_nft_pd[\"buckets\"] = pd.cut(df_nft_pd[\"number_of_items\"], bins=custom_bins, labels=bin_labels)\n",
    "\n",
    "# Convert the Interval object to a string representation of the bin interval\n",
    "df_nft_pd[\"buckets\"] = df_nft_pd[\"buckets\"].apply(lambda x: str(x))\n",
    "\n",
    "# Calculate the histogram of the binned column\n",
    "histogram = df_nft_pd.groupby(\"buckets\").size().reset_index(name=\"count\")\n",
    "histogram = histogram.sort_values(\"buckets\")\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Plot the histogram\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(histogram[\"buckets\"], histogram[\"count\"], width=1, edgecolor=\"black\", color=colors)\n",
    "ax.set_xlabel(\"Buckets\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Histogram of Binned Values for Ranking 6\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41500656",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_boundaries = custom_bins\n",
    "\n",
    "# Use the Bucketizer function to split the data into ranges\n",
    "bucketizer = Bucketizer(splits=range_boundaries, inputCol=\"number_of_items\", outputCol=\"bins_nft\")\n",
    "df_bucketized_nft = bucketizer.transform(df_nft)\n",
    "\n",
    "# Group the data by the \"buyer\" column and the range index, and compute the average duration\n",
    "\n",
    "# Show the resulting DataFrame with the average duration per buyer and range\n",
    "# df_bucketized_nft.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0220f07d",
   "metadata": {},
   "source": [
    "# Joining Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662b1fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = df_bucketized_spent \\\n",
    ".join(df_bucketized_avg_duration, on='buyer', how='inner') \\\n",
    ".join(df_bucketized_df_currency, on='buyer', how='inner') \\\n",
    ".join(df_bucketized_number_txns, on='buyer', how='inner') \\\n",
    ".join(df_bucketized_nft, on='buyer', how='inner') \\\n",
    ".join(df_bucketized_sum_net, on='buyer', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d41480",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eac890",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_1 = 10\n",
    "weight_2 = 10\n",
    "weight_3 = 5\n",
    "weight_4 = 10\n",
    "weight_5 = 10\n",
    "weight_6 = 10\n",
    "\n",
    "joined_df = joined_df.withColumn(\"Score\", reduce(lambda x, y: x + y, [(col(col_name) * const) for col_name, const in [(\"bins_spent\", weight_1), (\"bins_avg_duration\", weight_2), (\"bins_num_currency\", weight_3), (\"bins_number_txns\", weight_4), (\"bins_nft\", weight_5), (\"bins_sum_net\", weight_6)]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c06b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = joined_df.approxQuantile(\"Score\", [0.2, 0.8], 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.withColumn(\n",
    "    \"tier\",\n",
    "    when(col(\"Score\") <= percentiles[0], lit(\"tier1\"))\n",
    "    .when((col(\"Score\") > percentiles[0]) & (col(\"Score\") <= percentiles[1]), lit(\"tier2\"))\n",
    "    .otherwise(lit(\"tier3\"))\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:itp]",
   "language": "python",
   "name": "conda-env-itp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
